{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env reward scaling - pettingzoo\n",
    "\n",
    "Acts as a testbed for academics using 2 or 3d shaped data. \n",
    "\n",
    "Scales using MovingFoldChangeReward. \n",
    "\n",
    "### Background\n",
    "In Dualer models I put reward and intrinsic rewards in competition. This means the two values must be matched up. Or put another way, that need to have common units. There are many ways to do that. Let's consider a biological motivated approach to reward normalization inspired by:\n",
    "\n",
    "    - Adler, M., and Alon, U. (2018). Fold-change detection in biological\n",
    "    systems. Current Opinion in Systems Biology 8, 81â€“89.\n",
    "    - Karin, O., and Alon, U. (2021). The dopamine circuit as a reward-taxis navigation system. BioRxiv 439955, 30.\n",
    "\n",
    "We'll try several `envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from copy import deepcopy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from dualer.wrappers.academic import RFPrediction\n",
    "from dualer.wrappers.normalize import MovingFoldChangeReward\n",
    "from dualer.wrappers.normalize import ClipReward\n",
    "\n",
    "import pettingzoo\n",
    "from pettingzoo import mpe\n",
    "import supersuit as ss\n",
    "\n",
    "from infoduel_maddpg.utils.academic_wrappers import StatePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"simple_v2\"\n",
    "# env_name = \"simple_tag_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50\n",
    "latent_mode = \"mlp\"\n",
    "total_timesteps = 1000\n",
    "max_cycles = 25\n",
    "lr_academic = 0.001\n",
    "do_fold = True\n",
    "do_clip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_0': array([ 0.        ,  0.        , -0.06511435,  0.8512194 ], dtype=float32)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Env = getattr(mpe, env_name)\n",
    "env = Env.parallel_env(max_cycles=max_cycles, continuous_actions=True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space(env.possible_agents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9317701  0.23136078 0.61476906]\n",
      " [0.62085595 0.55878321 0.58706657]\n",
      " [0.54758801 0.3344116  0.54128054]\n",
      " [0.34900793 0.62144991 0.18971545]\n",
      " [0.13397827 0.40148372 0.49485851]\n",
      " [0.65316473 0.25592372 0.92957907]\n",
      " [0.70411778 0.69050959 0.17696261]\n",
      " [0.69724967 0.94661423 0.27797765]\n",
      " [0.50311391 0.81548859 0.77624513]\n",
      " [0.51879887 0.92546242 0.95557266]]\n",
      "[[0.69724967 0.94661423 0.27797765]\n",
      " [0.50311391 0.81548859 0.77624513]\n",
      " [0.51879887 0.92546242 0.95557266]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10, 3)\n",
    "print(x)\n",
    "print(x[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StatePrediction(env, network_hidden=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adversary_0': array([0.59769356, 0.05751409, 0.79003614, 0.24761441, 0.4978155 ],\n",
      "      dtype=float32), 'adversary_1': array([0.11352156, 0.03985091, 0.41391292, 0.8710639 , 0.4948355 ],\n",
      "      dtype=float32), 'adversary_2': array([0.4889414 , 0.90396065, 0.05769864, 0.6752599 , 0.67560387],\n",
      "      dtype=float32), 'agent_0': array([0.52922493, 0.24319053, 0.657722  , 0.2211245 , 0.45881745],\n",
      "      dtype=float32)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'adversary_0': array([ 0.02599132,  0.30075386, -0.39166135,  0.80715   ,  0.778772  ,\n",
       "         -0.75070363, -0.2045369 , -0.37165737, -0.32204536, -0.7704419 ,\n",
       "          0.4751598 , -1.2035803 ,  1.3148565 , -1.7713962 , -0.39270455,\n",
       "         -0.09498468], dtype=float32),\n",
       "  'adversary_1': array([-0.2956975 ,  0.13106494, -0.71370673,  0.03670814,  1.1008173 ,\n",
       "          0.01973824,  0.11750847,  0.3987845 ,  0.32204536,  0.7704419 ,\n",
       "          0.79720515, -0.43313837,  1.6369019 , -1.0009543 , -0.39270455,\n",
       "         -0.09498468], dtype=float32),\n",
       "  'adversary_2': array([ 0.30572632, -0.21128106,  0.08349845, -0.39643022,  0.30361217,\n",
       "          0.45287663, -0.6796967 ,  0.8319229 , -0.4751598 ,  1.2035803 ,\n",
       "         -0.79720515,  0.43313837,  0.83969676, -0.5678159 , -0.39270455,\n",
       "         -0.09498468], dtype=float32),\n",
       "  'agent_0': array([-0.39270455, -0.09498468,  0.9231952 , -0.96424615, -0.53608453,\n",
       "          1.0206925 , -1.5193934 ,  1.3997388 , -1.3148565 ,  1.7713962 ,\n",
       "         -1.6369019 ,  1.0009543 , -0.83969676,  0.5678159 ], dtype=float32)},\n",
       " {'adversary_0': 0.11547552794218063,\n",
       "  'adversary_1': 0.06396151334047318,\n",
       "  'adversary_2': 0.07919348031282425,\n",
       "  'agent_0': 0.1412838250398636},\n",
       " {'adversary_0': False,\n",
       "  'adversary_1': False,\n",
       "  'adversary_2': False,\n",
       "  'agent_0': False},\n",
       " {'adversary_0': {'env_reward': 0.0616605281829834,\n",
       "   'intrinsic_reward': 0.11547552794218063,\n",
       "   'network_loss': 0.2600146234035492},\n",
       "  'adversary_1': {'env_reward': 0.1123628318309784,\n",
       "   'intrinsic_reward': 0.06396151334047318,\n",
       "   'network_loss': 0.20950058102607727},\n",
       "  'adversary_2': {'env_reward': 0.08410898596048355,\n",
       "   'intrinsic_reward': 0.07919348031282425,\n",
       "   'network_loss': 0.11423660814762115},\n",
       "  'agent_0': {'env_reward': 0.11350752413272858,\n",
       "   'intrinsic_reward': 0.1412838250398636,\n",
       "   'network_loss': 0.17337116599082947}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.reset()\n",
    "actions = {}\n",
    "for a in env.env.agents:\n",
    "    actions[a] = env.env.action_space(a).sample()\n",
    "print(actions)\n",
    "env.step(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.seed(1)\n",
    "# AEC\n",
    "# env.reset()\n",
    "# next_obs, rewards, dones, infos = env.last()\n",
    "\n",
    "# parallel\n",
    "next_obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.possible_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryWriter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((10, 3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e89847e936c8c95f8cbdafeaa6e7c814f27278d8de21943cca2b199a4582e4c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
